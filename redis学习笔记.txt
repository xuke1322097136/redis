1. 垂直拆分：其实就是将一个Mysql数据库拆分成多个Mysql数据库，每个数据库负责一部分业务数据，如：用户信息/买家/卖家等等都可以单独是一个数据库。
2.  主从复制和读写分离：Master/Slave结构，Master负责写，Slave负责读。
3. 分库分表：为了缓解写的压力，又出现了分库分表的概念。即将业务相关的数据（高度活跃的数据）放在一个库里，另外的变化很少的数据（即，一些趋冷的数据。身份证信息等）放到另外一些数据库里。
                   假定一张表里的数据有9000w条数据，查询的数据肯定是很慢的，所以我们可以将它拆分成3个库，即假定1-3k的进1号库，3k到6k的进2号库，6k到9k的进3号库。
                   所以也就出现了Mysql集群（我们的例子里就是3个集群，每个集群里都有Master/Slave）。
4. redis一秒钟大概可以读10w次，写8w次。redis其实就是：KV+cache+persistence（当别人让你谈一谈redis的时候，可以这么简单回答）
5. 关系型数据库是ACID，非关系型数据库就是CAP+BASE。
6. NoSQL数据库的四大分类：KV键值（美团redis/tair，阿里memcache/redis，新浪Berkeley DB/redis）；文档型数据库(bson格式的居多，常见的有mongodb/couchdb等)；
                                           列存储数据库(cassandra/hbase，还有分布式文件系统)；图关系数据库（不是存放图片的，而是用于构建关系图谱的，存放的是关系，比如社交网络/推荐系统等，如Neo4j,InfoGrid）。

7. CAP(Consistency:强一致性；A：Availability:高可用；P：Partition tolerance:分区容错性)，分布式时代一定要实现P，因为当前的网络硬件等一定会出现延迟丢包等问题。
    CA：传统的Oracle数据库等，我们commit了就是commit了，数据也很及时；
    AP：大多数网站的架构（金融电商等，因为可以满足点赞数商品数什么的不是实时的即满足弱一致性，数据可以暂时是不对的，但是一定是不能崩掉的）；
    CP： redis/mongo等
    BASE：(Basically Available：基本可用；S：Soft sate:软状态；E：Eventually consistent:最终一致性)，它的思想是通过让系统放松某一时刻数据一致性的要求来换取系统整体伸缩性和性能上的改观（即牺牲强一致性换取AP），
    最终服务以BASE的理论基础达到 高可用的最终一致性。
    比如说双十一，你为了满足AP，牺牲了强一致性，但是双十一过了之后，你必须得把数据补上，满足BASE理论。
8. 分布式与集群：分布式：不同的多台服务器上部署不同的功能模块，它们之间通过RPC/RMI之间通信和调用，对外提供服务和组内协作。
                          集群：不同的多台服务器上部署相同的服务模块，通过分布式调度软件进行统一的调度，堆外提供服务和访问。
9. redis：REmote DIctionary Server(远程字典服务器)，它是完全开源免费的，用C语言编写的，遵守BSD协议，是一个高性能的key/value分布式内存数据库，基于内存运行并且支持持久化的NoSQL数据库，是当前最热门
              的NoSQL数据库之一，也被人们称为数据结构服务器。
           redis相比其他的key-value缓存产品(如memcache)有如下三个特点：1）Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载到内存使用；
            2）Redis不仅仅支持简单的key-value类型的数据，同时还提供list/set/zset/hash等数据结构的存储；3）Redis支持数据的备份，即master-slave模式的数据备份。
10. redis是单线程来处理客户端的请求的，对读和写等事件的响应是通过epoll函数的包装来做到的，Redis的实际处理速率完全依靠主进程的执行效率。
      Epoll是Linux内核为处理大批量文件描述符而改进的epoll，是linux下多路复用IO接口select/poll的增强版本，它能显著地提高程序在大量并发连接中只有少量获取的情况下系统CPU利用率。
11. redis默认是16个库，数组下标从0开始，表示的是0号库，一直到15。我们可以使用select命令在数据库之间切换。
12. Dbsize可以查看当前数据库的key数量，Flushdb用来清空当前数据库，Flushall清空所有的16个库，redis默认的端口号是6379。
13. redis.conf在windows下在哪？
14. key常见命令操作：待补充         键？值的键？
15. 持久化：RDB和AOF，RDB的全称是Redis DataBase,AOF的全称是Append Only File
    查看有没有起哪个服务：ps -ef | grep redis; lsof -i:6379; netstate XXX

    RDB的定义：在指定的时间间隔内将内存中的数据集快照写到磁盘中，也就是snapshot快照，
                       它恢复的时候是将快照文件直接读取到内存中。
     工作原理： Redis会单独创建(fork)一个子进程来进行持久化，会将数据写入到一个临时文件中，
                     待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何IO操作的，
                     这就确保了较高的性能。如果需要进行大规模的数据恢复，且对数据恢复的完整性不是非常敏感的话，那么RDB方式
                     要比AOF方式更加高效，RDB的缺点是最后一次持久化后的数据可能丢失。

   如何触发RDB快照：
    RDB什么时候会备份dump.rdb文件？即RDB的相关恢复策略：
     1）. 默认出厂配置的格式：  save  秒钟  写操作次数（下面三种满足一种就会生成一份dump.rdb文件，详见redis.conf文件）
                                  1分钟内改了1w次；
                               或5分钟内改了10次；
                               或15分钟内改了1次。
     但是如果想禁用RDB的持久化策略，只要不设置save指令或者给 save传入一个空字符串参数(即save "")就可以。
     2) save命令或者bgsave命令： 
       a.)save命令:还有一种情况就是当你输入了一条数据之后，想立刻就备份起来，那么你可以直接手动敲一个save，redis将会重新生成一个dump.rdb将你刚才输入的数据也备份起来。
       其实，说的就是这个意思：  set key1 111(这条数据很紧急，必须得马上备份，等不了15分钟，所以你可以接着再手动敲一个save命令即可)     
       b.) bgsave命令: redis会在后台异步进行快照操作，快照同时还可以相应客户端请求，即在备份的同时还要处理前台的数据。
           可以通过lastsave命令获取最后一次成功执行快照的时间 。                        
     3）shutdown/flushall命令的时候也会自动备份一份快照文件dump.rdb，但是需要注意的是，当你敲了flushall命令的时候，现在所有的key都会被清空了，此时生成的dump.rdb是你清空之后的dump文件，
         当你再次恢复的时候最新的dump文件是个空文件。所以说flushall之后恢复是无意义的。

     如何恢复快照？
      只需要将备份文件(dump.rdb)移动到redis的安装目录下并启动服务即可（此时可以借助config get dir命令获得当前目录文件，pwd不行？）。

    Stop-writes-on-bgsave-error:当后台在save操作出错了，前台要停止写。如果配置成no的话，那么这个工作将会扔给运维小哥。如果配置成no的话，
    表示你根本不在乎数据的一致性或者有其他的手段发现和控制(扔给运维小哥)
    rdbcompression：对于存储到磁盘中的快照，可以设置是否进行压缩存储，如果是的话，redis会采用LZF算法进行压缩，如果不想小号CPU来进行压缩的话，
    可以设置为关闭此功能。一般会设置成yes。
    rdbchecksum：在存储快照的时候，还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大会10%的性能消耗，如果希望获取到最大的性能
    提升的话，可以关闭此功能。一般也是会设置成yes。
    dbfilename：这个值就是默认设置的备份文件，出厂设置是dump.rdb文件。
    dir：目录文件，出厂设置是./，可以通过config get dir命令获得。

                                          rdbSave
                                       --------------> 
            内存中的数据对象 <-------------   磁盘中的RDB文件
                                           rdbLoad

    RDB的优势：1.) 适合大规模的数据备份；
          2.) 对数据完整性和一致性要求不高。（网络拥堵或丢包的话，数据可能丢失最后一次备份的数据）

    劣势：1.）在一定间隔时间内做一次备份，所以如果redis意外down掉（网络拥堵、丢包等问题）的话，就有可能会丢失掉最后一次快照后的所有修改。
              2.）Fork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑。
  
    AOF部分：
       1） AOF定义：以日志的形式来记录每个写操作，将Redis执行过的所有写指令记录下来（读操作不记录），只需追加文件但不可以改写文件，
                              redis启动之初会读取该文件重新构建数据，换言之，redis重启的话，会根据读取到内存中的日志文件的内容将写指令从前到尾
                              执行一次以完成数据的恢复工作。

       2） AOF启动、修复及恢复操作：
              正常恢复：a.）如果是启动的话，需要将appendonly设置成yes。将有数据的AOF文件复制一份到对应的目录(一般是bin目录，可以用config get dir得到)；
                              b.）恢复的时候，需要重启redis然后重新加载appendonly.aof文件。  
              异常恢复：a.) 启动的时候也要将appendonly设置成yes，然后备份一份被写坏的AOF文件；
                              b.) 修复的时候，可以利用redis-check-aof --fix命令来进行修复(rdb文件也是一样的修复过程，redis-check-aof是一个文件，也有redis-check-dump文件)
                              c.) 恢复的时候，重启redis然后重新加载appendonly.aof文件。
       3） AOF配置策略：
         redis.conf里面的相关配置：
                  a.) appendonly：要修改成yes，表示开启AOF持久化;
                  b.) appendfilename：一般不要乱改这个名字，就用默认的appendonly.aof；
                  c.) appendfsync：共有三种选择，
                            (1）Always：同步持久化，每次发生数据变更就会立即被记录到磁盘中，性能较差但是数据完整性较高；
                            (2)  Everysec：出厂默认设置，异步操作，每秒记录，如果一秒内宕机，将会有数据丢失；
                            (3)  No：不做记录。
                  d.) no-appendfsync-on-rewrite：重写时是否可以运用appendfsync，用默认的no即可，保证数据安全性。
                  e.) auto-aof-rewrite-min-size：设置重写的基准值，默认值是64MB;
                  f.) auto-aof-rewrite-percentage：设置重写的基准值，默认值是100%，该参数一般跟上面的auto-aof-rewrite-min-size搭配使用。
          4）重写rewrite：
                   a.) 定义：AOF采用文件追加方式，文件会越来越大，为了避免这种情况的出现，新增了重写机制，当AOF文件的大小超过设定的与之的
                                 时候，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集，可以使用命令bgrewriteaof。
                   b.) 重写原理：AOF文件持续增长而过大的时候，会fork一条新进程来将文件重写(也是先写临时文件最后再rename)，
                                        遍历新进程的内容中的数据，每条记录有一条set语句。重写aof文件的操作，并没有读取旧的aof文件，
                                        而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件，这点和快照有点像。
                   c.) 触发机制：redis会记录上次重写时的AOF文件大小， 默认配置是当AOF文件大小是
                                       上次rewrite后大小的一倍(auto-aof-rewrite-percentage配置成100%)且文件大于64MB（ auto-aof-rewrite-min-size参数）时触发。
             5) AOF优势及劣势：
                   优势：
                         a.) 每一次修改就同步：appendfsync设置成always，同步持久化，每次发生数据变更就会被记录到磁盘；
                         b.) 每秒同步：appendfsync设置成eveyesc，异步操作，每秒记录。
                         c.) 不同步：appendfsync设置成no，表示从不同步 。
                     劣势：
                          a.) 对于相同数据集而言，aof文件要远大于rdb文件，恢复的时候要明显慢于rdb； 
                          b.) aof运行效率要低于rdb，因为aof需要逐条逐条的恢复。每秒同步策略效率较好，不同步效率和rdb相同。
                    
           aof工作过程：
                                     命令请求                     网络协议格式的命令内容
                        客户端  ------------>   服务器  -------------------------------> AOF文件  
            
总结RDB和AOF：1. RDB持久化方式能够在指定时间间隔内对数据进行快速快照存储；
                          2. AOF持久化方式记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据，
                              AOF命令以redis协议追加保存每次写的操作到文件末尾，redis还能对AOF文件运行后台重启，使得AOF文件的提及不至于过大。
                          3. 只做缓存：如果只希望数据在服务器端存在，那么我们可以不使用持久化操作；
                          4. 同时开启两种持久化方式的情况下，
                                  a.)  redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下，
                                        AOF文件保存的数据集要比RDB文件保存的数据要完整。
                                  b.) RDB的数据不够实时，同时使用两者时服务器重启也只会找AOF文件，那么要不要只是用AOF？
                                       答案是最好不要！因为RDB更适用于备份数据库(AOF在不断变化不好备份)，快速重启，而且不会有AOF可能潜在的bug，
                                       因为AOF在恢复的时候也有可能出现恢复出错，因此留着rdb作为一个万一的手段。

性能建议：因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留save 900 1这条规则。
                
                如果Enable AOF的话，好处是在最恶劣情况下也只会丢失不超过2秒钟的数据，启动脚本较简单，只要load自己的AOF文件就可以了，
                代价一是带来了持续的IO操作，二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的，只要
                硬盘许可，应该尽量减少AOF rewrite的频率，AOF重写的基础大小默认值是64MB，可以设置成5G以上，默认超过原大小100%大小时
                重写可以改到适当的数值。

               如果不Enable AOF，仅靠Master-Slave Replication 实现高可用性也可以，能省掉一大笔IO，也减少了rewrite时带来的系统波动，代价是
               如果Master/Slave同时宕掉，会丢失十几分钟的数据，启动脚本也要比较两个Master/Slave中的RDB文件，载入较新的那个，新浪微博用的就是这种架构。

16. Redis事务：
           1.） 相关命令：discard：取消事务，放弃执行事务块内的所有命令；
                                  exec：执行所有事务块内的命令；
                                  multi：标记一个事务块的开始；
                                  unwatch：取消watch命令对【所有】key的监视；
                                  watch：监视一个或多个key，如果在事务执行之前(即exec之前)这个(或这些)key被其他命令所改动，那么事务将会被打断。
             2.）watch监控：
                      悲观锁(Pessimistic Lock)：每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，
                               这样别人想拿这个数据的时候就会block直到它拿到锁，传统的关系型数据库里就用到了这种锁机制，比如行锁，表锁等，
                               读锁，写锁等，都是在做操作之前先上锁。
                       乐观锁(Optimistic Lock)：每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人
                               有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量。
                               乐观锁其实其实是加了一个version的字段，所以在乐观锁的策略下，提交的版本必须大于记录当前版本才能执行更新。

                       watch指令，其实就类似于乐观锁，事务提交的时候，如果key的值已被别的客户端改变了，比如某个list已被别的客户端push/pop
                                  过了，整个事务队列都不会被执行。
                                              客户端1                                     客户端2
                            举个例子：  WATCH balance
                                               MULTI                                    set balance 800
                                               set balance 80
                                               set debt 20
                                               EXEC
                                        客户端1这边最后的结果是 nil。（代表事务就没有执行成功）
                                        因为此时客户端中的balance已经被客户端2修改过了，所以必须先拿到balance的值，然后接着watch重新执行事务。
                       通过watch命令在事务执行之前监控了多个keys，倘若在watch之后有任何key值发生了变化，exec命令执行的事务都将会被放弃，
                       同时返回Nullmulti-bulk应答来通知调用者事务执行失败。

            总结：事务的3个阶段：
                           a.) 开启：以multi开始一个事务；
                           b.) 入队：将多个命令入队到事务中，接着这些命令并不会立即执行，而是放到等待执行的事务的队列里面；
                           c.) 执行：由exec命令触发事务。
                      事务的3个特性：
                             a.) 单独的隔离操作：事务中的所有命令都会序列化，按顺序地执行。事务在执行的过程中，不会被其他客户端发送过来的命令请求所打断。
                             b.)  没有隔离级别的概念：队列中的命令没有提交之前都不会实际地被执行，因为事务提交之前任何指令都不会被实际执行，也就不存在
                                    ”事务内的查询要看到事务里的更新，在事务外查询不能看到“这个让人万分头疼的问题；
                             c.) 不保证原子性：redis同一个事务中如果有一条命令执行失败的话，其后的命令仍然会被执行，没有回滚。
                                     【注】这里所说的命令仍然会执行指的是在执行的时候是能正常加入队列的，但是真正exec的时候该命令会报错，
                                              如果该命令刚开始就是不能加入队列的，那么整个事务将会执行失败，不会出现部分会被执行的情况。
                                              例如：我们执行：     incr k1(此时k1是一个字符串)    这条命令是能加入到队列中的，直到exec的时候才会报错，这就是上面说的情况。
                                                        但是我们输入一个不存在的命令，如getset k1，此时就直接会报error，这样在exec的时候整个事务里的操作都不会执行。

17. 主从复制：主机数据更新后根据配置和策略，自动同步到备机的master/slave机制，Master以写为主，Slave以读为主。(即slave想写是写不进去的)
                      能做到读写分离和容灾恢复的效果。

                      怎么操作？
                            1.） 原则：配从(库)不配主(库)：即在从库上配置命令：
                                                      slaveof 主库IP地址  主库端口号
                                    【注意】每次slave与master断开之后，都需要重新连接，除非你配置进redis.conf文件里。
                                                 可以利用【info replication命令】查看该端口的角色以及它们的主从关系。
                            2.） 修改配置文件细节操作，一般需要修改redis.conf文件里面的参数有：
                                         a.) 需要拷贝多个redis.conf文件，可以分别命名为redis6379.conf/redis_6380.conf/redis_6381.conf;
                                         b.) 开启dameonize yes；
                                         c.) pid文件名字，可以分别设置成var/run/redis6379.pid    var/run/redis6380.pid   var/run/redis6381.pid
                                         d.) 指定端口：6379/6380/6381
                                         e.) log文件名字：可以指定为6379.log/6380.log/6381.log；
                                         f.) dump.rdb文件名也可以分别改为dump6379.rdb/dump6380.rdb/dump6381.rdb
                             3.）需要打开四个窗口，一个是监听6379端口，一个监听6380端口，一个监听6381端口以及一个root用户窗口。
                                    测试情形1：
                                         一主二从：在6380和6381两个端口上分别输入了slaveof 127.0.0.1 6379 之后，它们就能从6379的机子上全量备份到自己的机子上。
                                                         此时要是Master宕机了之后（SHUNDOWN和exit命令之后），slave会等着啥也不干，还是slave的角色，直到6379的机子重新启动了之后，
                                                         6380和6381会继续分担着slave的角色；
                                                         此时要是Slave宕机的话，那么它再次重启的时候，它将会变成slave角色，只是跟6379个和6381所连结起来的体系分开了，它单独是一个master，
                                                         正如上面所说的，每次slave与master断开之后，都需要重新连接，即重新执行slaveof 127.0.0.1 6379命令。刚开始脸上会全量备份一份6379的数据，
                                                         后面也是增量备份master的数据。
                                        薪火相传：其实就是去中心化的意思。上一个Slave可以是下一个slave的Master，Slave同样可以接收其他slaves的连接和同步请求，那么该slave作为链条中
                                                        下一个的master，可以有效减轻master的写压力。这种情况中途变更转向的时候，会清除掉之前的数据，重新建立拷贝最新的数据。
                                                         此时用到的命令是：       slaveof   新主库IP   新主库端口
                                                         我们在上面的一主二从上修改，将6381的master改成6380，即在6381上执行  slaveof 127.0.0.1 6380
                                                          此时我们在6379和6380上利用info replication都可以看到它们下面的connected_slave只跟着一个slave。但是在6381上用info replication上面看到它的角色还是slave。
                                        反客为主：其实就是slave变成master。之前的一主二从讲过了，一旦某个slave宕掉之后，它不会主动的承担master，只会一直等到吩咐。
                                                        模拟一下：首先回到最开始一主二从，我们让6379宕掉，然后6380输入【slaveof no one 】，此时我们再用info replication命令的时候，可以看到它变成了master角色，
                                                                        但是6381并没有自动地变成6380的slave，而还是6379的slave，所以我们需要手动地在6381上利用slaveof 127.0.0.1 6380，它才会变成6380的slave。
                                                                        同样，要是此时6379恢复过来了，它仍然是Master的角色，只是此时它将自立门户，跟6380和6381没有关系。

主从复制的原理：slave启动成功连接到Master后会发送一条sync命令，master在接收到命令后会启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，
                          master将传送整个数据文件到slave，以完成一次完全体同步。
                       a.) 全量复制：slave服务在接收到数据库文件的数据之后，将其存盘并存盘到内存中；
                       b.) 增量复制：Master继续将新的所有收集到的修改命令一次传给slave，完成同步，但是只要是重新连接master，一次完全同步(全量复制)将会自动执行。
                                            其实可以归纳为：  首次全量，以后增量。
 
哨兵模式(sentinel)：可以理解为自动版的反客为主。因为上面的反客为主需要我们自己操作和自己指定，而在这都是自动完成。它能够在后台监控主机是否故障，
                              如果故障了根据投票数自动将从库转换为主库。
                               具体操作：
                                      a.) 首先还是回到最开始的一主二从，即6379带着6380和6381；
                                      b.) 自定义的/myredis目录（不一定是这个目录，其他目录也可以）下新建一个sentinel.conf文件，名字绝对不能错；
                                      c.）配置哨兵，即在sentinel.conf文件中填写内容，sentinel monitor 被监控的数据库名字(自己起啥名都可以) 127.0.0.1 6379 1
                                                      127.0.0.1是你监听的主机名字，6379就是Master的端口，1表示主机挂掉之后slave投票看让谁接替成为主机，
                                                       得票数超过1的成为新的master。 
                                     d.) 启动哨兵：redis-sentinel  /myredis/sentinel.conf(redis-sentinel是和redis-server/redis-cli是位于同一bin目录下的) 
                                     e.) 然后模拟6379这台机子挂掉了，即执行shutdown和exit命令；
                                     f.) 稍等一会之后，可以看到 sentinel.conf文件里面有了新的变化，即重新选了6380作为了新的master。为了验证这一点，我们
                                           可以在6380中输入  info replication命令，可以看到它变成了master,接着在6381中输入info replication命令，
                                           它自动变成了6380的slave。令人诧异的是，此时我们再次重启6379这台机子的时候，6379也已经变成了6380的slave。
                                           也就是说，现在6380是master,6379和6381变成了slave。
                                      【注意】一组sentinel也是可以同时监控多个master的。
复制操作的缺点：由于所有的写操作都是先在master上操作，然后同步更新到slave上，所以从master上同步到slave机器上有一定的延迟，当系统很频繁的时候，
                           这个问题会更加严重，slave机器数量的增加也会使得这个问题更加严重。         

                                                          

                            

















                